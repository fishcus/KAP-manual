## Kyligence Enterprise 常见问题

以下收集了用户在学习使用Kyligence Enterprise过程中经常遇到的一些问题。

### 设计方面

**Q: Kyligence Enterprise 最大能支持的维度有多少？**

A: 这个问题不是简单一个数字能回答的；首先，本产品的多维立方体“物理”维度最多62个，但用户可以通过使用维表+定义"衍生"（Derived）维度的方式，将一个维度衍生出更多维，从而达到支持上百个维度查询的Cube。通常建议Cube的物理维度（除去衍生维度）在15个以内，当有更多维度的时候，务必分析用户查询模式和数据分布特征，采取维度分组，定义mandantory、hierarchy和joint等高级手段，避免维度间的肆意组合（“维度的灾难”），从而使得Cube的构建时间和所占空间在可控范围。


**Q: 维度可以动态增加吗？减少呢？**

A: 当增减维度时，Cube需要重新计算；如果不想重新计算历史Cube，可以定义新Cube，然后将新老Cube做一个组合（Hybrid），一起响应用户查询。

**Q: 本产品构建Cube的过程要多久？有时很慢，如何优化？**

A: 通常Cube构建在几十分钟到几小时，取决于数据量、模型复杂度、维度基数、集群计算能力和配置等多方面。优化需要具体问题具体分析。

**Q: 构建Cube时，经常OOM，如何调整？**

A：OOM需要看具体在哪一步发生，采取不同措施；如果是在“Build Dictionary”发生，需要审视Cube定义，看是否有对超高基数维度使用了字典编码（可改用其它编码方式）；如果是在"Build Cube"时候发生，需要检查Yarn的内存分配设置；要关闭InMem模式，可以在conf/kylin.properties里设置kylin.cube.algorithm=layer

**Q: 维度超过10个时，构建过程跑不起来，如何优化？**

A：参见前一个问题的回答。

**Q：Derived维度和Normal维度是什么意思**

A：Derived维度相对于Normal来说，他并不参与维度的组合计算，他的FK参与维度组合计算，从而降低维度组合数，在查询时，对Dervied维度的查询会首先转换为对FK维度的查询，因此会牺牲少数性能。

**Q：Hierarchy Dimension有顺序关系吗？**

A：有关系，要从大到小的顺序声明。

**Q: 如果有多张事实表，该如何使用本产品？**

A: 可以为每个事实表定义一个Cube，然后使用sub query来组合这几张表的查询。或者使用Hive View将多张事实表join成一张宽表，然后用这张宽表定义模型和Cube，查询按宽表进行。

**Q: Segment的数量影响查询的性能吗？大的Segment可以拆分成小的吗？**

A：Segment的数量会影响查询性能，因为本产品需要顺序扫描每个Segment，所以通常建议定期进行Segment合并。通常来说，更少的Segment意味着更好的查询性能，因此无需拆分大的Segment（也拆分不了）。

**Q: 源数据模型变化了怎么办？**

A：具体问题具体分析；增加字段是没有问题的，删除或修改字段可能会导致metadata混乱。所以建议不要修改原始数据模型；如果无法避免，建议在源模型上创建Hive View，然后基于View来定义Cube；当源模型改变时（如列名更改），只需更新View即可，Cube不受影响。

**Q: 关系型数据库如何使用本产品？**

A：使用工具（如sqoop）先将数据从RDBMS导入到Hive。

**Q: 本产品会支持雪花模型吗？**

A: 支持。

**Q：定义多个Aggregation Group，查询条件可以跨Aggregation Group吗**

A：Aggreation Group目的是降维，最好查询的条件只在一个Aggregation Group中，如果跨越了Aggregation Group，则需要从Base Cuboid进行Post Processing，会影响查询的性能。

**Q：使用Hive创建大平表性能会比星型模型更好吗？**

A：性能没有区别，但星型模型的维度可以使用derived dimension，存储上更紧凑。

**Q：压缩配置对构建Cube有什么作用？**

A:   当需要处理的数据体量变得越来越大时，网络I/O的限制也越来越大。开启压缩可以让每个I/O操作处理更多的数据，压缩也可以改进网络传输的性能。尽管CPU压缩和解压缩数据需要花费一些时间，但是通常这些时间是远远小于I/O和网络I/O消耗的时间，从而使得整个MR任务更快完成。

> 如何设置压缩配置，请参考手册[压缩配置](http://docs.kyligence.io/books/v2.5/zh-cn/config/compression_settings.cn.html)章节

### 查询引擎

**Q：什么是查询引擎？**

A：Kyligence Enterprise支持三种查询引擎：Cube引擎，表索引（Table Index）引擎，下压（Pushdown）引擎

Cube引擎是被广泛使用的，为聚合类查询所设计的查询引擎，用于OLAP分析场景。

表索引引擎是列式存储引擎，为明细查询场景设计。在分析场景中，用户可以通过钻取聚合数据到最底层的明细数据。

下压引擎是其他SQL on Hadoop引擎，包括Hive，SparkSQL，Impala等。当某个查询不适合预计算引擎时，查询会被下压到其他下游查询引擎。这种情况下，查询延迟通常会延长到分钟级。

**Q：多查询引擎如何一起工作？**

A：有两种类型的查询，聚合查询和明细查询，带有“group by“的是聚合查询，其他查询是明细查询。

对于聚合查询，Kyligence Enterprise按照顺序：Cube引擎 > 表索引引擎 > 下压引擎

对于明细查询，Kyligence Enterprise按照顺序：表索引引擎 > Cube引擎 > 下压引擎

每个引擎都有自己的查询能力（通过维度、指标、列定义），如果查询与当前引擎不匹配，则查询会被路由到下一个引擎。

**Q：如何开启／关闭查询引擎**

A：每个查询引擎都可以独立地启动和关闭查询能力。如果表索引在Cube设计阶段并没有配置，则表索引引擎会忽略所有的查询。在某些场景，如果查询下压的引擎没有通过配置文件启动，则查询也会被下压引擎忽略。Cube也可以通过配置参数`kylin.query.disable-cube-noagg-sql`为true，关闭Cube对明细查询的处理。

### 查询方面

**Q：本产品支持MDX吗？**

A：可以通过Kyligence MDX Service组件支持。

**Q：怎么查看本产品的执行计划？**

A：可以在查询的前面添加``explain plan for``以获得执行计划，例如```explain plan for select count(*) from airline```。但是执行计划的结果的展示并没有被优化，可以通过前端的``导出结果``功能查看。

**Q：本产品支持模糊查询吗？**

A：支持like做为过滤条件。

**Q：支持的SQL标准是什么？有哪些函数？**

A：本产品支持SQL92标准，使用Apache Calcite做为sql parser，因此本产品的sql标准可以参考https://calcite.apache.org/docs/reference.html

**Q:   本产品会将列名返回为大写，如果需要小写的列名怎么办？**

A:   使用类似select column_A as "test" from table 的语句，将列的假名用双引号转义则可以返回大小写敏感的列名。

**Q：支持Distinct Count吗？**

A：支持，本产品提供两种统计去重（count distinct）指标的方式：基于 HyperLogLog 算法的模糊去重和基于Bitmap的精确去重。两种方式进行计算时需要的资源和性能不一样，用户可以根据需要选择使用。

**Q：模型中Inner Join多张表，但查询事实表时，为什么有时查询结果比Hive的少？**

A：这符合设计，本产品会首先从数据源读取原始数据，并按照模型的定义生成一张大平表。本产品在从Hive中抽取数据的时候，会按照Model中定义的方式Join所有表来取数据；如果有Inner Join，一些不能匹配的数据在拉取过程中会被直接过滤。如果查询是跟模型匹配的，带有所有表，那么查询结果就没有问题。如果查询只匹配部分表，有可能出现查询结果比在Hive中只查询部分表时少的情况。

在实际实践中，如果源数据质量不能保证的话，建议用Left Join；如果要用Inner Join，就要保证维度表与事实表的同步更新。

**Q：使用本产品还需要BI系统吗？**

A：本产品本身的核心在于强大的后端，针对数据分析提供亚秒级的响应。同时对外部各个BI平台也有很好的集成，也提供了丰富的API供进行二次开发。所以针对本产品需要配合其他的BI系统一起使用。

推荐本公司的Kyligence Insight for Superset，是一款功能强大，与Kyligence Enterprise无缝集成的BI解决方案。

### 对比方面

**Q：本产品与Spark、Impala有什么区别？**

A：从业内的使用经验来看，目前 Hadoop 平台上可用于查询分析的几种技术主要包括预计算（本产品）、内存计算（以Spark为代表）、倒排索引（以ElasticSearche为代表）和列式存储（以Impala为代表）。

从技术原理来看，预计算技术将数据事先按维度组合聚合，保存结果为物化视图。经过聚合，物化视图的规模将只由维度的基数决定，而不再随数据量的增长而线性增长。以电商为例，如果业务扩张，交易量增长了10倍，但只要交易数据的维度不变（供应商/商品数量不变），聚合后的物化视图将依旧是原先的大小。查询的速度也将保持不变，即计算时间复杂度相对数据量是O(1)的。

而内存计算、倒排索引、列式存储等技术，虽然其技术原理各不相同，但都是在查询执行时（runtime）对明细数据进行在线的汇总统计，因此这些技术在数据记录数较少时（百万~千万），性能还处于可接受范围。但随着数据量快速增长（硬件资源不增加），其查询速度也将随着数据量的增长而线性增长，因此其计算时间复杂度相对数据量为O(N)的。

各种技术的计算时间复杂度对比如下图所示。从大数据背景来看，网络日志、系统日志、物联网等各种数据在飞速而持续的产生着，从而对于大数据查询分析来说，其面对的数据量将是一个爆发式的增长模式，因此，预计算这种能够屏蔽数据量爆发增长带来的计算压力，保持计算时间复杂度O(1)的技术将是最理想也是最合适的技术。

![复杂度](images/complexity.png)

**Q：本产品与 Druid 有什么区别？**

A：Druid 最初的设计是为了实时分析，本产品更关注解决 OLAP 问题；最初 Druid 可以支持实时流 Kafka，现在 Kyligence Enterprise 也支持直接从 Kafka 读取消息，具备实时构建 Cube 的能力，提供近实时的分析处理能力；Druid 使用位图索引作为内部数据结构，本产品也使用位图为 Cube 建立索引；Druid使用自己定义的查询语言，而本产品支持ANSI SQL；Druid 在支持表连接方面有限制；本产品支持星型模型；Druid与先用的BI工具集成不够友好，本产品可以很好地支持大部分 BI 工具，如 Tableau，Excel；由于本产品支持 MOLAP Cube，在超大规模数据集上的复杂查询具备极高的性能。而 Druid需要扫描全部索引，如果数据集太大，或者查询范围太大，则性能损失更大；本产品依赖于Hadoop 构建 Cube，Druid 采用了自己的计算和存储技术，对于已经部署了 Hadoop 的情况，本产品的部署只是很小的额外工作，而 Druid 需要重新部署完整的集群。

